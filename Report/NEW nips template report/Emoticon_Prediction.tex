% From the template
\documentclass{article} % For LaTeX2e
\usepackage{nips14submit_e,times}
% Uncomment  hyperref to get ugly green and red boxes around the refs
%\usepackage{hyperref}
\usepackage{url}
%\documentstyle[nips14submit_09,times,art10]{article} % For LaTeX 2.09

% Old from the report
\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{xcolor,colortbl}
\usepackage[]{algorithm2e}
\usepackage{verbatim}
%\usepackage{soul}

% Bibliography
\usepackage[backend=bibtex]{biblatex}
\addbibresource{ourbib.bib}

\newcommand{\tab}{\hspace{10mm}}
\newcommand{\dtab}{\hspace{20mm}}
\newcommand{\ttab}{\hspace{30mm}}
\newcommand{\qtab}{\hspace{40mm}}



\title{Emoticon Prediction in Text} 


% Found better (i think) way to write them (in two columns)
\begin{comment}
% Also add student IDs (Ivan wants them)
\author{ 
Iva Gornishka \\ \texttt{iva.gornishka@student.uva.nl} \\ 10415548 \AND
Cassandra Loor \\ \texttt{cassandra.loor@student.uva.nl} \\ \AND   
Arif Qodari \\ \texttt{arif.qodari@gmail.com} \\ \AND
Finde Xumara \\ \texttt{finde.findexumara@student.uva.nl} \\ }
\end{comment}



% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.



\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}


% Somebody has a better idea about this footstep? :)
\maketitle\footnote{This project is part of the Natural Language Processing 1 course taught at the University of Amsterdam in 2014-2015}


% Doesn't this author list look better? :/ You can guys pick whatever you like
% Also, how do we put it a bit more up? :/ 
\begin{center}
\begin{tabular}{cc}
\textbf{Iva Gornishka} 	&	\textbf{Cassandra Loor} \\
\texttt{iva.gornishka@student.uva.nl} & \texttt{cassandra.loor@student.uva.nl} \\
10415548 & ID \\ \\
\textbf{Finde Xumara} & \textbf{Arif Qodari} \\
\texttt{finde.findexumara@student.uva.nl} & \texttt{arif.qodari@gmail.com} \\
ID & ID \\ \\ \\
\end{tabular}{}
\end{center}


% Leaving it for now to check number of pages and stuff.. Uncomment/comment when needed
% \tableofcontents
% \pagebreak


% Original template Abstract info
\begin{comment}
\begin{abstract}
The abstract paragraph should be indented 1/2~inch (3~picas) on both left and
right-hand margins. Use 10~point type, with a vertical spacing of 11~points.
The word \textbf{Abstract} must be centered, bold, and in point size 12. Two
line spaces precede the abstract. The abstract must be limited to one
paragraph.
\end{abstract}
\end{comment}


% IVAN WANTS BOTH ABSTRACT AND INTRODUCTION. The old introduction sounds more like abstract maybe. But then what should we put in the introduction??? :/ Actually new `Problem' sounds like an introduction.... TODO: fix this mess :D 

%%%%%%%%%%%%%%%%
%%%%%  Abstract  %%%%%%
%%%%%%%%%%%%%%%%

\begin{abstract}
% Try to sound smarter here :D
Emoticon prediction in text is a problem closely related to opinion mining, sentiment analysis and reputation extraction. This report discusses two different ways of prediction emotions. In the first case, emoticons are predicted based on a single short message. This lead to the use of an average multiclass perceptron. In the second case, chat data is used to predict emoticons, based not only on the current message, but also on the previous ones as well. This lead to the use of a Hidden Markov Model and the Viterbi decoding algorithm.
\end{abstract}

%%%%%%%%%%%%%%%%
%%%%% Introcuction %%%%%
%%%%%%%%%%%%%%%%
\section{Introduction}

% Requirements: 
\begin{comment}
Introduction (max 2 pages):
• Description of the problem area and the problem itself
• What is the research question / goal?
• Why is this an important / meaningful / interesting problem to consider?
• The very basic idea of the approach and why this is a reasonable approach for this problem?
\end{comment}


This report discusses two related, but essentially different problems - emoticon prediction based on a single short message and based on a sequence of messages. In the first problem, some amount of unrelated short messages should be observed, together with the contained emoticons, a classifier should be trained and at the end, given a new message the corresponding emotion should be predicted. This means that the messages might (and should) be written by different authors in order to achieve good generalization. In the second problem, a whole conversation should be observed and the classification should be done not only by considering the features of a single message, but instead, by also considering the previous messages of the same user. This problem is a more complex and interesting one, since it also takes into account the transitions from one sentiment state to another. \\

\noindent As a natural consequence of the above statements of the two problems, two different data sets should be used for them. For the first one it might be any corpora of text messages, containing a decent amount of emoticons. Such corpora might contain for example any unrelated text messages from social media. For the current research, a Twitter data was chosen. For the second problem, a corpora containing longer sequences of text messages should be used - these might be different conversations, such as an e-mail exchange or just chat data, as long as they contain sufficient amount of emoticons. For the current research an Ubuntu chat data was chosen. \\

\noindent After the data is collected, it is first preprocessed. Afterwards appropriate features are extracted and a model is trained. The current report does not discuss the choice of features in detail. Some basic feature were chosen for this project without intentional aim on improving them. Since this task on its own deserves a lot of time and effort, it is left as future work and suggestions about it are mentioned in the following sections. \\

\ldots \ldots \ldots 

%%% Continue the rest of the discussion of the problem by only mentioning something brief about the models and possible alternatives. More details are in the corresponding sections!!



%%%%%%%%%%%%%%%%
%%%%%  Problem  %%%%%%
%%%%%%%%%%%%%%%%
\section{Problem}

% Requirements:
\begin{comment}
Problem: (roughly 1-2 pages)
• Explain the problem; what kind of assumptions / observations you have about the problem
\end{comment}


% Don't leave blank pages, space is precious :D We can leave space if we fir in ~10 pages :)
% \pagebreak


%%%%%%%%%%%%%%%%
%%%%%% Twitter  %%%%%%
%%%%%%%%%%%%%%%%
\section{Twitter emoticon prediction}

% Requirements:
\begin{comment}
Approach (roughly 2-3 pages)
• Explain the model; if any important assumptions are made at this stage, explain why they are
reasonable or necessary
• Explain learning / inference algorithms
• Explaining (perhaps briefly) any necessary preprocessing / postprocesing / data acquisition stages
(maybe earlier, depending on the project; may also move to the experimental section)
\end{comment}


In this part of the project Twitter data was used in order to train a classifier for predicting emoticons. Three basic classes were used in order to classify the data. Table \ref{tab:classes} presents these classes and the corresponding emoticons, contained in this type of data.


% Old and ugly
\begin{comment}
\begin{itemize}
% TODO: Fix the emoticon examples to match the emoticons actually used
\item \textbf{positive} - data containing `positive' emoticons (expressing positive emotions) such as `:)', `:]', `=)', or `:D'
\item \textbf{neutral} - data containing no emoticons or neutral emoticons like `:$\vert$' or `o\_o'
\item \textbf{negative} - data containing `negative' emoticons (expressing negative emotions) such as `:(', `:[', `=(` or `;(' 
\end{itemize}
\end{comment}


% Maybe put this in the general part, since it is the same for both problems?
\begin{table}[h!]
\caption{Data classes}
\label{tab:classes}
\begin{center}
\begin{tabular}{ll}
\multicolumn{1}{l}{\bf DATA CLASS}  &\multicolumn{1}{l}{\bf EXAMPLE EMOTICONS}
\\ \hline \\
positive 			& :) \: \:  			:] \: \: 		=) \: \: 		:D  	\\
neutral 				& :$\vert$ \: \: 	o\_o  								\\
negative 			& :( \: \: 			:[ \: \: 		=( \: \: 		;( 		\\
\end{tabular}{}
\end{center}
\end{table}

%%%%%%%%%%%%%%%%
%%%%%% Data %%%%%%%
%%%%%%%%%%%%%%%%
\subsection{Data}

In order to collect data from Twitter, a crawler was used. The Twitter crawler searched for training and test data, based on emoticons. These messages (`tweets') contain much information - the name of the author, text, hyperlinks, hashtags (sequences of the form `\#word\_sequence'). Since there are no official restrictions, messages often contain plenty of intentional or - more often - unintentional spelling and grammar errors. Messages also sometimes contain words from other languages, which makes preprocessing and analyzing the data even harder.


%%%%%%%%%%%%%%%%
%%%% Preprocessing %%%%%
%%%%%%%%%%%%%%%%
\subsection{Preprocessing \label{sec:preprocessing}}

Before any of the data can be used, the messages need to be preprocessed. This process includes three basic steps. Each one of them is discussed in more details in the following paragraphs.



% Since the bulleting doesn't match much the tamplate, find better way to present it. Maybe subsubsections?
\begin{comment}
\begin{itemize}
% TODO: PRECISELY EXPLAIN THE PREPROCESSING HERE :) 
\item \textbf{Splitting the message} into different components - text, hashtags and emoticons.
\item \textbf{Spelling check and correction} 
\item \textbf{Grammar check and correction} 
\end{itemize}
\end{comment}


% I saw that this is how people put such not really `important' subsubsections instead of bullets
\subsubsection*{Splitting the message.}
\subsubsection*{Spelling check and correction}
\subsubsection*{Grammar check and correction}



%%%%%%%%%%%%%%%%
%%%%%%  Model  %%%%%%
%%%%%%%%%%%%%%%%
\subsection{Model}


A multi-class perceptron was chosen as most appropriate for the purpose of this project. 


%%%%%%%%%%%%%%%%
%%%%%  Features  %%%%%%
%%%%%%%%%%%%%%%%
\subsection{Features \label{sec:features}}

Once the data is collected and preprocessed, its features are extracted. Choosing good features might significantly improve the performance in many cases, but this task is not a trivial one. Due to time limitations, some basic features were chosen for the current research, but it is believed that future research might be done in order to explore a bigger set of features. Table ~\ref{featuretable} presents the features which were extracted and used for classification. Since most of the features' names are self-explanatory, only the some of the features are discussed in details in the following paragraphs.


% Old features, not really fitting the template...
\begin{comment}
\begin{itemize}
\item \textbf{words} - total number of words in the text 
\item \textbf{positive words} - total number of positive words in the text
\item \textbf{negative words} - total number of negative words in the text 
\item \textbf{positive words hashtags} - total number of positive words in the hashtags 
\item \textbf{negative words hashtags} - total number of negative words in the hashtags 
\item \textbf{uppercase words} - number of words containing only uppercase letters 
\item \textbf{special punctuation} - number of special punctuation marks such as `!' and `?' 
\item \textbf{adjectives} - number of adjectives in the text  
\end{itemize}
\end{comment}

\begin{table}[h!]
\caption{Extracted features}
\label{featuretable}
\begin{center}
\begin{tabular}{ll}
\multicolumn{1}{l}{\bf FEATURE NAME}  &\multicolumn{1}{l}{\bf DESCRIPTION}
\\ \hline \\
words & total number of words in the text \\
positive words & total number of positive words in the text \\
negative words & total number of negative words in the text \\
positive words hashtags & total number of positive words in the hashtags \\
negative words hashtags & total number of negative words in the hashtags \\
uppercase words & number of words containing only uppercase letters \\
special punctuation & number of special punctuation marks such as `!' and `?' \\
adjectives & number of adjectives in the text 
\end{tabular}{}
\end{center}
\end{table}



\noindent Extracting features such as \textbf{positive words} and \textbf{negative words} requires the usage of a predefined lists of `positive' and `negative' words. Both these lists contain ...... % TODO: DESCRIBE THE LISTS AND STATE WERE THEY WERE TAKEN FROM 
\\
\\
Features such as the number of \textbf{adjectives} were extracted by first performing POS tagging on each sentence and then counting the adjectives in the tagged sentence. Due to spelling and grammar errors in the messages, POS tagging does not always perform  perfect. As a consequence, slight inaccuracies are possible for this feature, though not significant enough to influence the performance.



%%%%%%%%%%%%%%%%
%%%%%% Results %%%%%%
%%%%%%%%%%%%%%%%
\subsection{Experiments and Results}

% Requirements:
\begin{comment}
Experiments / Empirical evaluation (roughly 2-3 pages)
• Any details about experiments (dataset sizes, parameter selection, etc)
• Results
• Analysis (discussion of results / visualization / findings / etc)
\end{comment}


% Don't leave blank pages, space is precious :D We can leave space if we fir in ~10 pages :)
% \pagebreak



%%%%%%%%%%%%%%%%
%%%%%% Ubuntu %%%%%%
%%%%%%%%%%%%%%%%
\section{Ubuntu emoticon prediction}

% Requirements:
\begin{comment}
Approach (roughly 2-3 pages)
• Explain the model; if any important assumptions are made at this stage, explain why they are
reasonable or necessary
• Explain learning / inference algorithms
• Explaining (perhaps briefly) any necessary preprocessing / postprocesing / data acquisition stages
(maybe earlier, depending on the project; may also move to the experimental section)
\end{comment}



%%%%%%%%%%%%%%%%
%%%%%% Data %%%%%%%
%%%%%%%%%%%%%%%%
\subsection{Data}


%%%%%%%%%%%%%%%%
%%%% Preprocessing %%%%%
%%%%%%%%%%%%%%%%
\subsection{Preprocessing}

% Is it actually? Actually are we even preprocessing here or did we assume it was already preprocessed?
Before any of the data can be used, the messages need to be preprocessed. This is done again in the way explained in section ~\ref{sec:preprocessing}. 



%%%%%%%%%%%%%%%%
%%%%%%  Model  %%%%%%
%%%%%%%%%%%%%%%%
\subsection{Model}


A Hidden Markov Model was chosen as post appropriate for the purpose of this project. This section summarizes the steps which were taken in order to train the model and predict classes for unseen examples afterwards. \\

\noindent As explained earlier, after the data has been pre-processed, a feature vector is extracted for each example message. Thus, the training data for the model consists of pair $(X, y)$, where $X$ is a feature vector and $y$ is the corresponding class label. The next step is to compute the transition and emission probabilities, i.e. the probability of transitioning from one class state to another and the probabilities of the different feature vectors given a class state. \\

\noindent  Consider a simple example: the probability of observing a `sad' massage right after a `neutral' message has been observed is a transition probability. Furthermore, the probability of the feature vector of the message `I need to get some sleep now' given the neutral class is an emission probability. This means that the following general formulas might be used in order to calculate these probabilities:

\begin{align*}
\cal{P} (\textit{transitioning from class y' to class y''}) 
&= \frac {\# \textit{ of times class y'' is observed after class y'}} {\textit {total \# of training examples}} \\
\cal{P} (\textit{feature vector $X$ given class y}) 
&= \frac {\# \textit{ of times the pair $(X, y)$ occurs in the training data }} {\textit {total \# of training examples from class y}} \\
\end{align*}

\noindent Since the total number of feature vectors $X$ which can be observed is too big, not all possible vectors would be observed in the training data. This would make predicting unseen messages impossible, since no emission probabilities would be present for these vectors. In order to avoid this issue, the following solution is implemented: the training data is first clustered, emission probabilities are computed for each cluster, then given an unseen message, its feature vector is first assigned to a cluster and finally, a label is predicted for this message. 

%%%%%%%%%%%%%%%%
%%%%%  Features  %%%%%%
%%%%%%%%%%%%%%%%
\subsection{Features}

\noindent The features used in this part of the project correspond to the ones already discussed in section ~\ref{sec:features}. Note that some features, such as numbers of positive or negative words in hashtags are not applicable in the current setting, since the data does not contain hashtags. Thus, such features have not been considered. 


%%%%%%%%%%%%%%%%
%%%%%% Results %%%%%%
%%%%%%%%%%%%%%%%
\subsection{Experiments and Results}

% Requirements:
\begin{comment}
Experiments / Empirical evaluation (roughly 2-3 pages)
• Any details about experiments (dataset sizes, parameter selection, etc)
• Results
• Analysis (discussion of results / visualization / findings / etc)
\end{comment}



%%%%%%%%%%%%%%%%
%%%%  Conculsion  %%%%%%
%%%%%%%%%%%%%%%%
\section{Conclusion}

% Requirements:
\begin{comment}
Discussion and Conclusions (0.5 – 1 page)
• Refer to the research questions you defined in your introduction.
• Any related work you are aware of?
• Challenges you observed?
• “Future work” (you do not need to do this work really J, but what would you change in the
model / what experiments you would run / etc, if you would have a chance to do this? What other
people should look into?
• Any thoughts / observation / wider implications
\end{comment}


%%%%%%%%%%%%%%%%
%%%%   Future work  %%%%%
%%%%%%%%%%%%%%%%
\section{Future work}




%%%% He has to be kidding about this one, but... :/ 
\section*{Team responsibilities}

% Requirements:
\begin{comment}
Team responsibilities (1 paragraph)
• Who did what
\end{comment}



% Does not really fit the idea of the template, should it stay? Maybe better a readme file to be included?
\begin{comment}
\section*{Files attached}
\begin{itemize}
\item Code
\end{itemize}
\end{comment}

% No need of sources anymore, still move these papers to the bibliography
\begin{comment}
\section*{Sources}
\addcontentsline{toc}{section}{Sources}
\begin{itemize}
	\item Bird, Steven, Edward Loper and Ewan Klein (2009), Natural Language Processing with Python. O’Reilly Media Inc.
	\item Author: Ryan Kelly, Home Page: https://pythonhosted.org/pyenchant/
\end{itemize}
\end{comment}

I'm gonna cite something here \cite{greenwade93} to see how it works ;)

\nocite{*}
\printbibliography
% The bibliography still contains useless things. To be changed later






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\noindent\makebox[\linewidth]{\rule{\paperwidth}{2pt}} \\%%
\noindent\makebox[\linewidth]{\rule{\paperwidth}{2pt}} \\%%
\noindent\makebox[\linewidth]{\rule{\paperwidth}{2pt}} \\%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

GENERAL THINGS AND INFO FROM THE TEMPLATE AFTER HERE!!!! \\


\section{Submission of papers to NIPS 2014}

NIPS requires electronic submissions.  The electronic submission site is  
\begin{center}
   \url{http://papers.nips.cc}
\end{center}

Please read carefully the
instructions below, and follow them faithfully.
\subsection{Style}

Papers to be submitted to NIPS 2014 must be prepared according to the
instructions presented here. Papers may be only up to eight pages long,
including figures. Since 2009 an additional ninth page \textit{containing only
cited references} is allowed. Papers that exceed nine pages will not be
reviewed, or in any other way considered for presentation at the conference.
%This is a strict upper bound. 

Please note that this year we have introduced automatic line number generation
into the style file (for \LaTeXe and Word versions). This is to help reviewers
refer to specific lines of the paper when they make their comments. Please do
NOT refer to these line numbers in your paper as they will be removed from the
style file for the final version of accepted papers.

The margins in 2014 are the same as since 2007, which allow for $\approx 15\%$
more words in the paper compared to earlier years. We are also again using 
double-blind reviewing. Both of these require the use of new style files.

Authors are required to use the NIPS \LaTeX{} style files obtainable at the
NIPS website as indicated below. Please make sure you use the current files and
not previous versions. Tweaking the style files may be grounds for rejection.

%% \subsection{Double-blind reviewing}

%% This year we are doing double-blind reviewing: the reviewers will not know 
%% who the authors of the paper are. For submission, the NIPS style file will 
%% automatically anonymize the author list at the beginning of the paper.

%% Please write your paper in such a way to preserve anonymity. Refer to
%% previous work by the author(s) in the third person, rather than first
%% person. Do not provide Web links to supporting material at an identifiable
%% web site.

%%\subsection{Electronic submission}
%%
%% \textbf{THE SUBMISSION DEADLINE IS June 6, 2014. SUBMISSIONS MUST BE LOGGED BY
%% 23:00, June 6, 2014, UNIVERSAL TIME}

%% You must enter your submission in the electronic submission form available at
%% the NIPS website listed above. You will be asked to enter paper title, name of
%% all authors, keyword(s), and data about the contact
%% author (name, full address, telephone, fax, and email). You will need to
%% upload an electronic (postscript or pdf) version of your paper.

%% You can upload more than one version of your paper, until the
%% submission deadline. We strongly recommended uploading your paper in
%% advance of the deadline, so you can avoid last-minute server congestion.
%%
%% Note that your submission is only valid if you get an e-mail
%% confirmation from the server. If you do not get such an e-mail, please
%% try uploading again. 


\subsection{Retrieval of style files}

The style files for NIPS and other conference information are available on the World Wide Web at
\begin{center}
   \url{http://www.nips.cc/}
\end{center}
The file \verb+nips2014.pdf+ contains these 
instructions and illustrates the
various formatting requirements your NIPS paper must satisfy. \LaTeX{}
users can choose between two style files:
\verb+nips11submit_09.sty+ (to be used with \LaTeX{} version 2.09) and
\verb+nips11submit_e.sty+ (to be used with \LaTeX{}2e). The file
\verb+nips2014.tex+ may be used as a ``shell'' for writing your paper. All you
have to do is replace the author, title, abstract, and text of the paper with
your own. The file
\verb+nips2014.rtf+ is provided as a shell for MS Word users.

The formatting instructions contained in these style files are summarized in
sections \ref{gen_inst}, \ref{headings}, and \ref{others} below.

%% \subsection{Keywords for paper submission}
%% Your NIPS paper can be submitted with any of the following keywords (more than one keyword is possible for each paper):

%% \begin{verbatim}
%% Bioinformatics
%% Biological Vision
%% Brain Imaging and Brain Computer Interfacing
%% Clustering
%% Cognitive Science
%% Control and Reinforcement Learning
%% Dimensionality Reduction and Manifolds
%% Feature Selection
%% Gaussian Processes
%% Graphical Models
%% Hardware Technologies
%% Kernels
%% Learning Theory
%% Machine Vision
%% Margins and Boosting
%% Neural Networks
%% Neuroscience
%% Other Algorithms and Architectures
%% Other Applications
%% Semi-supervised Learning
%% Speech and Signal Processing
%% Text and Language Applications

%% \end{verbatim}

\section{General formatting instructions}
\label{gen_inst}

The text must be confined within a rectangle 5.5~inches (33~picas) wide and
9~inches (54~picas) long. The left margin is 1.5~inch (9~picas).
Use 10~point type with a vertical spacing of 11~points. Times New Roman is the
preferred typeface throughout. Paragraphs are separated by 1/2~line space,
with no indentation.

Paper title is 17~point, initial caps/lower case, bold, centered between
2~horizontal rules. Top rule is 4~points thick and bottom rule is 1~point
thick. Allow 1/4~inch space above and below title to rules. All pages should
start at 1~inch (6~picas) from the top of the page.

%The version of the paper submitted for review should have ``Anonymous Author(s)'' as the author of the paper.

For the final version, authors' names are
set in boldface, and each name is centered above the corresponding
address. The lead author's name is to be listed first (left-most), and
the co-authors' names (if different address) are set to follow. If
there is only one co-author, list both author and co-author side by side.

Please pay special attention to the instructions in section \ref{others}
regarding figures, tables, acknowledgments, and references.

\section{Headings: first level}
\label{headings}

First level headings are lower case (except for first word and proper nouns),
flush left, bold and in point size 12. One line space before the first level
heading and 1/2~line space after the first level heading.

\subsection{Headings: second level}

Second level headings are lower case (except for first word and proper nouns),
flush left, bold and in point size 10. One line space before the second level
heading and 1/2~line space after the second level heading.

\subsubsection{Headings: third level}

Third level headings are lower case (except for first word and proper nouns),
flush left, bold and in point size 10. One line space before the third level
heading and 1/2~line space after the third level heading.

\section{Citations, figures, tables, references}
\label{others}

These instructions apply to everyone, regardless of the formatter being used.

\subsection{Citations within the text}

Citations within the text should be numbered consecutively. The corresponding
number is to appear enclosed in square brackets, such as [1] or [2]-[5]. The
corresponding references are to be listed in the same order at the end of the
paper, in the \textbf{References} section. (Note: the standard
\textsc{Bib\TeX} style \texttt{unsrt} produces this.) As to the format of the
references themselves, any style is acceptable as long as it is used
consistently.

As submission is double blind, refer to your own published work in the 
third person. That is, use ``In the previous work of Jones et al.\ [4]'',
not ``In our previous work [4]''. If you cite your other papers that
are not widely available (e.g.\ a journal paper under review), use
anonymous author names in the citation, e.g.\ an author of the
form ``A.\ Anonymous''. 


\subsection{Footnotes}

Indicate footnotes with a number\footnote{Sample of the first footnote} in the
text. Place the footnotes at the bottom of the page on which they appear.
Precede the footnote with a horizontal rule of 2~inches
(12~picas).\footnote{Sample of the second footnote}

\subsection{Figures}

All artwork must be neat, clean, and legible. Lines should be dark
enough for purposes of reproduction; art work should not be
hand-drawn. The figure number and caption always appear after the
figure. Place one line space before the figure caption, and one line
space after the figure. The figure caption is lower case (except for
first word and proper nouns); figures are numbered consecutively.

Make sure the figure caption does not get separated from the figure.
Leave sufficient space to avoid splitting the figure and figure caption.

You may use color figures. 
However, it is best for the
figure captions and the paper body to make sense if the paper is printed
either in black/white or in color.
\begin{figure}[h]
\begin{center}
%\framebox[4.0in]{$\;$}
\fbox{\rule[-.5cm]{0cm}{4cm} \rule[-.5cm]{4cm}{0cm}}
\end{center}
\caption{Sample figure caption.}
\end{figure}

\subsection{Tables}

All tables must be centered, neat, clean and legible. Do not use hand-drawn
tables. The table number and title always appear before the table. See
Table~\ref{sample-table}.

Place one line space before the table title, one line space after the table
title, and one line space after the table. The table title must be lower case
(except for first word and proper nouns); tables are numbered consecutively.

\begin{table}[t]
\caption{Sample table title}
\label{sample-table}
\begin{center}
\begin{tabular}{ll}
\multicolumn{1}{c}{\bf PART}  &\multicolumn{1}{c}{\bf DESCRIPTION}
\\ \hline \\
Dendrite         &Input terminal \\
Axon             &Output terminal \\
Soma             &Cell body (contains cell nucleus) \\
\end{tabular}
\end{center}
\end{table}

\section{Final instructions}
Do not change any aspects of the formatting parameters in the style files.
In particular, do not modify the width or length of the rectangle the text
should fit into, and do not change font sizes (except perhaps in the
\textbf{References} section; see below). Please note that pages should be
numbered.

\section{Preparing PostScript or PDF files}

Please prepare PostScript or PDF files with paper size ``US Letter'', and
not, for example, ``A4''. The -t
letter option on dvips will produce US Letter files.

Fonts were the main cause of problems in the past years. Your PDF file must
only contain Type 1 or Embedded TrueType fonts. Here are a few instructions
to achieve this.

\begin{itemize}

\item You can check which fonts a PDF files uses.  In Acrobat Reader,
select the menu Files$>$Document Properties$>$Fonts and select Show All Fonts. You can
also use the program \verb+pdffonts+ which comes with \verb+xpdf+ and is
available out-of-the-box on most Linux machines.

\item The IEEE has recommendations for generating PDF files whose fonts
are also acceptable for NIPS. Please see
\url{http://www.emfield.org/icuwb2010/downloads/IEEE-PDF-SpecV32.pdf}

\item LaTeX users:

\begin{itemize}

\item Consider directly generating PDF files using \verb+pdflatex+
(especially if you are a MiKTeX user). 
PDF figures must be substituted for EPS figures, however.

\item Otherwise, please generate your PostScript and PDF files with the following commands:
\begin{verbatim} 
dvips mypaper.dvi -t letter -Ppdf -G0 -o mypaper.ps
ps2pdf mypaper.ps mypaper.pdf
\end{verbatim}

Check that the PDF files only contains Type 1 fonts. 
%For the final version, please send us both the Postscript file and
%the PDF file. 

\item xfig "patterned" shapes are implemented with 
bitmap fonts.  Use "solid" shapes instead. 
\item The \verb+\bbold+ package almost always uses bitmap
fonts.  You can try the equivalent AMS Fonts with command
\begin{verbatim}
\usepackage[psamsfonts]{amssymb}
\end{verbatim}
 or use the following workaround for reals, natural and complex: 
\begin{verbatim}
\newcommand{\RR}{I\!\!R} %real numbers
\newcommand{\Nat}{I\!\!N} %natural numbers 
\newcommand{\CC}{I\!\!\!\!C} %complex numbers
\end{verbatim}

\item Sometimes the problematic fonts are used in figures
included in LaTeX files. The ghostscript program \verb+eps2eps+ is the simplest
way to clean such figures. For black and white figures, slightly better
results can be achieved with program \verb+potrace+.
\end{itemize}
\item MSWord and Windows users (via PDF file):
\begin{itemize}
\item Install the Microsoft Save as PDF Office 2007 Add-in from
\url{http://www.microsoft.com/downloads/details.aspx?displaylang=en\&familyid=4d951911-3e7e-4ae6-b059-a2e79ed87041}
\item Select ``Save or Publish to PDF'' from the Office or File menu
\end{itemize}
\item MSWord and Mac OS X users (via PDF file):
\begin{itemize}
\item From the print menu, click the PDF drop-down box, and select ``Save
as PDF...''
\end{itemize}
\item MSWord and Windows users (via PS file):
\begin{itemize}
\item To create a new printer
on your computer, install the AdobePS printer driver and the Adobe Distiller PPD file from
\url{http://www.adobe.com/support/downloads/detail.jsp?ftpID=204} {\it Note:} You must reboot your PC after installing the
AdobePS driver for it to take effect.
\item To produce the ps file, select ``Print'' from the MS app, choose
the installed AdobePS printer, click on ``Properties'', click on ``Advanced.''
\item Set ``TrueType Font'' to be ``Download as Softfont''
\item Open the ``PostScript Options'' folder
\item Select ``PostScript Output Option'' to be ``Optimize for Portability''
\item Select ``TrueType Font Download Option'' to be ``Outline''
\item Select ``Send PostScript Error Handler'' to be ``No''
\item Click ``OK'' three times, print your file.
\item Now, use Adobe Acrobat Distiller or ps2pdf to create a PDF file from
the PS file. In Acrobat, check the option ``Embed all fonts'' if
applicable.
\end{itemize}

\end{itemize}
If your file contains Type 3 fonts or non embedded TrueType fonts, we will
ask you to fix it. 

\subsection{Margins in LaTeX}
 
Most of the margin problems come from figures positioned by hand using
\verb+\special+ or other commands. We suggest using the command
\verb+\includegraphics+
from the graphicx package. Always specify the figure width as a multiple of
the line width as in the example below using .eps graphics
\begin{verbatim}
   \usepackage[dvips]{graphicx} ... 
   \includegraphics[width=0.8\linewidth]{myfile.eps} 
\end{verbatim}
or % Apr 2009 addition
\begin{verbatim}
   \usepackage[pdftex]{graphicx} ... 
   \includegraphics[width=0.8\linewidth]{myfile.pdf} 
\end{verbatim}
for .pdf graphics. 
See section 4.4 in the graphics bundle documentation (\url{http://www.ctan.org/tex-archive/macros/latex/required/graphics/grfguide.ps}) 
 
A number of width problems arise when LaTeX cannot properly hyphenate a
line. Please give LaTeX hyphenation hints using the \verb+\-+ command.


\subsubsection*{Acknowledgments}

Use unnumbered third level headings for the acknowledgments. All
acknowledgments go at the end of the paper. Do not include 
acknowledgments in the anonymized submission, only in the 
final paper. 


\subsubsection*{References}

References follow the acknowledgments. Use unnumbered third level heading for
the references. Any choice of citation style is acceptable as long as you are
consistent. It is permissible to reduce the font size to `small' (9-point) 
when listing the references. {\bf Remember that this year you can use
a ninth page as long as it contains \emph{only} cited references.}

\small{
[1] Alexander, J.A. \& Mozer, M.C. (1995) Template-based algorithms
for connectionist rule extraction. In G. Tesauro, D. S. Touretzky
and T.K. Leen (eds.), {\it Advances in Neural Information Processing
Systems 7}, pp. 609-616. Cambridge, MA: MIT Press.

[2] Bower, J.M. \& Beeman, D. (1995) {\it The Book of GENESIS: Exploring
Realistic Neural Models with the GEneral NEural SImulation System.}
New York: TELOS/Springer-Verlag.

[3] Hasselmo, M.E., Schnell, E. \& Barkai, E. (1995) Dynamics of learning
and recall at excitatory recurrent synapses and cholinergic modulation
in rat hippocampal region CA3. {\it Journal of Neuroscience}
{\bf 15}(7):5249-5262.
}

\end{document}
