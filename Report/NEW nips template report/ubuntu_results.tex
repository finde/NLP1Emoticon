
% Requirements:
\begin{comment}
Experiments / Empirical evaluation (roughly 2-3 pages)
• Any details about experiments (dataset sizes, parameter selection, etc)
• Results
• Analysis (discussion of results / visualization / findings / etc)
\end{comment}

Different experiments were run to test the performance of the Hidden Markov Model. Sample results are shown in tables and are discussed in more detail in this section. Table \ref{table:HMMaccuracy} shows the accuracy for two classes (positive and negative) and all three classes (including neutral). The model was trained on 90\% of the selected data and tested on the 10\% that is left. Each test is run on all data available, unless specified otherwise. The amount of clusters is set to 50.

\begin{table}[h!]
\begin{center}
\begin{tabular}{| c | c | c | c | c | c | c |}
\hline
 {\textbf{Classes}} 			& {\textbf{Features}}	& {\textbf{Clusters}} 
 & {\textbf{Train Accuracy (\%)}} 					& {\textbf{Test Accuracy (\%)}} 
 \\
\hline
2 			& all 	& 50			& 73.65		& 72.66 		\\ %not changed as the new version broke this
3 			& all	& 50			& 39.23		& 38.37 		\\
\hline
\end{tabular}
\caption{HMM accuracy}
\label{table:HMMaccuracy}
\end{center}
\end{table}

\begin{comment}
\begin{table}[h!]
\begin{center}
\begin{tabular}{| c | c | c | c | c | c |}
\hline
 {\textbf{Classes}} 	
 & {\textbf{Data per class}} 					& {\textbf{Clusters}} 
 & {\textbf{Train Accuracy (\%)}} 					& {\textbf{Test Accuracy (\%)}} 
 \\
\hline
2 			& 500 		& 50			& 73.65		& 72.66 		\\ %not changed as the new version broke this
3 			& 500 		& 50			& 39.23		& 38.37 		\\
\hline
\end{tabular}
\caption{HMM accuracy}
\label{table:HMMaccuracy}
\end{center}
\end{table}
\end{comment}

\subsubsection*{Classes} 
Table \ref{table:HMMaccuracy} shows that the use of two classes yields best results. However, this happens due to the fact that the results are biased. As the chat data comes from a support forum, most messages are indeed negative or neutral. As the emission and transition values are calculated by counting labels, the HMM itself will most likely transition to negative or neutral. This also leads to few data labelled as positive always being correct. However, this does not happen often, due to the aforementioned calculations. Finding a better way to select data to train the model on will be imperative in the future in order to produce better results. As the data of three classes is least biased, this will be used in further testing.

\subsubsection*{Features}
As with the AMP, the effect of the features on the HMM were tested. As this model trains on a sequence of messages, it could be that the features have a different effect.

\begin{table}[h!]
\begin{center}
\begin{tabular}{| c | c | c | c | c |}
\hline
 {\textbf{Features Excluded}} 	 	& \textbf{Classes}	& {\textbf{Iterations}} 
 & {\textbf{Train Accuracy (\%)}} 					& {\textbf{Test Accuracy (\%)}} 
 \\
\hline
None						&	3	&	50	&	39.23	&	38.37	\\
Positive/negative words	&	3	&	50	&	38.69	&	38.62	\\
Amount of words			&	3	&	50	&	38.61	&	38.02	\\
Special punctuation		&	3	&	50	&	38.81	&	38.25	\\
Adjectives				&	3	&	50	&	38.66	&	37.73	\\
\hline
\end{tabular}
\caption{AMP accuracy}
\label{table:HMMfeatures}
\end{center}
\end{table}

Table \ref{table:HMMfeatures} shows that the exclusion of more features shows no improvement. This confirms the suspicion of poorly selected features. However, this also does confirm that the current selection of features works optimal and should be used for further testing.

\subsection*{Amount of clusters}
Different amounts of clusters were used to test their effect on the model. The results are displayed in table \ref{table:HMMclusters}.
\begin{table}[h!]
\begin{center}
\begin{tabular}{| c | c | c | c |}
\hline
 {\textbf{Classes}} 	 	& {\textbf{Clusters}} 
 & {\textbf{Train Accuracy (\%)}} 					& {\textbf{Test Accuracy (\%)}} 
 \\
\hline
3 	 		& 10			& 38.27		& 37.94		\\
3 	 		& 20			& 38.53		& 38.36		\\
3 	 		& 30			& 39.00		& 37.45		\\
3 	 		& 40			& 38.99		& 38.22		\\
3 	 		& 50			& 39.23		& 38.37		\\
\hline
\end{tabular}
\caption{HMM amount of clusters}
\label{table:HMMclusters}
\end{center}
\end{table}

The results in table \ref{table:HMMclusters} shows that an increasing amount of clusters yields varying results. This could mean that the model overfits. However, there is not much difference between implementing few clusters and many clusters. The fact that the model does not yield good results can be attributed to the fact that the selected features are not sufficient. The minimal differences between the results leads to the suspicion that there is a bug in the implementation. However, due to time constraints, this bug was not identified and fixed.

\subsection{Dataset size}
This section discusses the effect of different dataset sizes on the HMM implementation. The results are displayed table \ref{table:HMMdataset}.

\begin{table}[h!]
\begin{center}
\begin{tabular}{| c | c | c | c | c | c | c |}
\hline
 {\textbf{Classes}} 	 
 & {\textbf{Data per class}} 					& {\textbf{Clusters}} 
 & {\textbf{Train Accuracy (\%)}} 					& {\textbf{Test Accuracy (\%)}} 
 \\
\hline
3 	 		& 50			& 50			& 45.17		& 39.65		\\
3 	 		& 100 		& 50			& 41.90		& 38.76		\\
3 	 		& 200 		& 50			& 40.91		& 38.48		\\
3 	 		& 300 		& 50			& 40.67		& 37.53		\\
3 	 		& 400 		& 50			& 40.41		& 37.34		\\
3 	 		& 500 		& 50			& 40.32		& 36.67		\\
3 	 		& 1000 		& 50			& 39.29		& 36.63		\\
3 	 		& 2500 		& 50			& 39.00		& 36.14		\\
\hline
\end{tabular}
\caption{HMM dataset size}
\label{table:HMMdataset}
\end{center}
\end{table}

Table \ref{table:HMMdataset} indicates that when least data is used, the model performs best. There is a significant change in the performance when testing on the training set. However, there is a smaller change in performance when testing on the test set. This leads to the conclusion that the model overfits quickly. As the data is balanced with few data, the performance is expected to perform poorly on all levels. Given that the model actually yields best results with little training, this confirms that there is a bug in the implementation. However, due to time constraints, this cannot be found and fixed.




%-------------------------------------------------------------------------------------------------

\begin{comment}
\subsection*{Amount of clusters}
Different amounts of clusters were used to test their effect on the model. The results are displayed in table \ref{table:HMMclusters}. This was tested on three classes. As stated before, the transitions between neutral and negative are more prominent, which will show the effect of the amount of clusters.

\begin{table}[h!]
\begin{center}
\begin{tabular}{| c | c | c | c | c | c | c |}
\hline
 {\textbf{Classes}} 	 
 & {\textbf{Data per class}} 					& {\textbf{Clusters}} 
 & {\textbf{Train Accuracy (\%)}} 					& {\textbf{Test Accuracy (\%)}} 
 \\
\hline
3 	 		& 500 		& 10			& 73.68		& 76.41		\\
3 	 		& 500 		& 20			& 73.71		& 76.38		\\
3 	 		& 500 		& 30			& 73.78		& 76.28		\\
3 	 		& 500 		& 40			& 74.11		& 75.88		\\
3 	 		& 500 		& 50			& 74.18		& 75.55		\\
\hline
\end{tabular}
\caption{HMM amount of clusters}
\label{table:HMMclusters}
\end{center}
\end{table}

The results in table \ref{table:HMMclusters} shows that an increasing amount of clusters yields worse results as more are added. This could mean that the model overfits. However, there is not much difference between implementing few clusters and many clusters. The fact that the model does not yield good results can be attributed to the fact that the selected features are not sufficient. The minimal differences between the results confirms the suspicion that there is a bug in the implementation. However, due to time constraints, this bug was not identified and fixed. On the other hand, in each case, the test set performs better than the training set. This means that the model generalizes well, which is the goal of the implementation of any model.
\end{comment}