In this part of the project the Ubuntu Chat Corpus was used as training data \cite{ubuntudata}. This corpus consists of archived chat logs from Ubuntu's Internet Relay Chat technical support channels. The logs contain continuous conversations, where numerous authors take part in the conversation. Some authors only post few messages, whereas others participate more actively in the conversations. As discussed earlier, this data does not contain enough emoticons, hence, relabeling the whole corpus was necessary. After an emoticon was predicted for each sentence, the data was ready to be used to feature extraction, training and testing.


\begin{comment}

\subsubsection*{Relabelling the data} 
Since this data contains mainly technical conversations, there appeared to be a significant lack of emoticons. This means that the majority of the messages were labelled as `neutral', which in turn implies a terribly biased prediction performance. In order to use this data and test the prediction performance, the decision was made to relabel the data. For every `neutral' message, an emoticon was predicted using the AMP discussed in section \ref{sec:twitter}. This lead to the acquisition of data containing enough emoticons to properly train a model and predict new examples. In order to avoid such artificial relabelling of the data in other projects, corpora from a more appropriate source should be used - e.g. Skype conversation logs or any other group chat logs.
\end{comment}